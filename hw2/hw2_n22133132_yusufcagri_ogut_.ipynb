{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k-1Dn8_kYdg"
      },
      "source": [
        "### HW2 - Multinomial Logistic Regression & SVMs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdX7Rlk5kYdn"
      },
      "source": [
        "### Training and Evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect gdrive for train/test datasets:"
      ],
      "metadata": {
        "id": "7jzAbe3u6Doe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # import lib\n",
        "drive.mount(\"/content/gdrive\") # mount gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnXWIu7ddxm3",
        "outputId": "c16189c5-badd-496d-b3b0-2c41c2ee8b74"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries:"
      ],
      "metadata": {
        "id": "isHlEzNW6G9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # for np array ops\n",
        "import matplotlib.pyplot as plt # for visualization purposes\n",
        "from pandas import * # for reading and parsing .csv files\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "MOtNL3x8cwW4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read Data:"
      ],
      "metadata": {
        "id": "v7gbLRAC6Moq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sTrainAdd = \"/content/gdrive/MyDrive/MsC/cmp712/hw2/train.csv\" # address of train.csv on gdrive \n",
        "sTestAdd = \"/content/gdrive/MyDrive/MsC/cmp712/hw2/test.csv\" # address of train.csv on gdrive \n",
        "data_training = read_csv(sTrainAdd)\n",
        "data_test = read_csv(sTestAdd)"
      ],
      "metadata": {
        "id": "vG_WJMtAcw64"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess Data:"
      ],
      "metadata": {
        "id": "mYp7VXm56Q9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data Preprocessing\n",
        "temp = data_training.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "sClass = \"type\"\n",
        "x_training = DataFrame()\n",
        "y_training = DataFrame()\n",
        "for idxColumns in range(nColumns):\n",
        "  temp1 = data_training.iloc[:, idxColumns]\n",
        "  if temp1._name==sClass:\n",
        "    y_training = y_training.append(temp1)\n",
        "  else:\n",
        "    x_training = x_training.append(temp1)\n",
        "x_training = x_training.T\n",
        "y_training = y_training.T\n",
        "# Test Data Preprocessing\n",
        "temp = data_test.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "sClass = \"type\"\n",
        "x_test = DataFrame()\n",
        "y_test = DataFrame()\n",
        "for idxColumns in range(nColumns):\n",
        "  temp1 = data_test.iloc[:, idxColumns]\n",
        "  if temp1._name==sClass:\n",
        "    y_test = y_test.append(temp1)\n",
        "  else:\n",
        "    x_test = x_test.append(temp1)\n",
        "x_test = x_test.T\n",
        "y_test = y_test.T"
      ],
      "metadata": {
        "id": "7DMrRdU4fF1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4275e448-28b5-4b49-d68c-1a76feb1f2d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  y_training = y_training.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-4-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode Datasets:"
      ],
      "metadata": {
        "id": "sCsaUTiG6TC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot Encoding for Training Dataset:\n",
        "le = LabelEncoder() # create label object\n",
        "x_training.diet = le.fit_transform(x_training.diet)\n",
        "x_training.lived_in = le.fit_transform(x_training.lived_in)\n",
        "x_training.period = le.fit_transform(x_training.period)\n",
        "x_training.named_by = le.fit_transform(x_training.named_by)\n",
        "x_training.taxonomy = le.fit_transform(x_training.taxonomy)\n",
        "x_training.species = le.fit_transform(x_training.species)\n",
        "# Limit dataset #\n",
        "x_training_processed = x_training.drop(columns=['id', 'name', 'length', 'link']) # x_, argument used in training\n",
        "print(x_training_processed)\n",
        "# One-hot Encoding for Test Dataset:\n",
        "x_test.diet = le.fit_transform(x_test.diet)\n",
        "x_test.lived_in = le.fit_transform(x_test.lived_in)\n",
        "x_test.period = le.fit_transform(x_test.period)\n",
        "x_test.named_by = le.fit_transform(x_test.named_by)\n",
        "x_test.taxonomy = le.fit_transform(x_test.taxonomy)\n",
        "x_test.species = le.fit_transform(x_test.species)\n",
        "# Limit dataset #\n",
        "x_test_processed = x_test.drop(columns=['id', 'name', 'length', 'link']) # x_, argument used in training\n",
        "print(x_test_processed)"
      ],
      "metadata": {
        "id": "eC9evK1ZOUoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90c7cbe-2b26-4179-96d1-a1f048d25a84"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     diet  period  lived_in  taxonomy  named_by  species\n",
            "0       0     108        25         0        76       61\n",
            "1       2     108         1        34        11       95\n",
            "2       1      65         5        20       212      188\n",
            "3       1      43        24        49        64      181\n",
            "4       1      21        25        17        22       24\n",
            "..    ...     ...       ...       ...       ...      ...\n",
            "241     1      11        13        25       186      184\n",
            "242     1      10         2        13       161      120\n",
            "243     0      14         5        79       203      222\n",
            "244     0      42         1        58        14      182\n",
            "245     3     112        19        34        70      170\n",
            "\n",
            "[246 rows x 6 columns]\n",
            "    diet  period  lived_in  taxonomy  named_by  species\n",
            "0      1      18        13        24        36       19\n",
            "1      1      41        17        21         8       51\n",
            "2      0      24        17        43        26       32\n",
            "3      0       2        17        30        50        6\n",
            "4      2      53        19        33        58       23\n",
            "..   ...     ...       ...       ...       ...      ...\n",
            "57     1      51         2        20        10       50\n",
            "58     1      38        10         9        29       43\n",
            "59     0      39        11        31        47        1\n",
            "60     1      22         1         2        59       60\n",
            "61     1      22         1         3        49       58\n",
            "\n",
            "[62 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression #\n",
        "# Training and mean_accuracy #\n",
        "skf = StratifiedKFold(n_splits=5)  #the number of folds is 5\n",
        "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "accuracy_scores = []\n",
        "for train_index, test_index in skf.split(x_training_processed, y_training):\n",
        "  X_train, X_test = x_training_processed.iloc[train_index], x_training_processed.iloc[test_index]\n",
        "  y_train, y_test = y_training.iloc[train_index], y_training.iloc[test_index]  \n",
        "  model.fit(X_train, y_train)\n",
        "  accuracy = model.score(X_test, y_test)\n",
        "  accuracy_scores.append(accuracy)\n",
        "# Compute the mean accuracy across all folds\n",
        "np.savetxt('training_LR.csv', model.predict(x_training_processed), delimiter=',', fmt='%s') # save result to text\n",
        "np.savetxt('test_LR.csv', model.predict(x_test_processed), delimiter=',', fmt='%s') # save result to text\n",
        "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "print(\"Logistic Regression - Mean accuracy:\", mean_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCAAOQ-VrU5T",
        "outputId": "08035381-4009-46b5-e5db-c8a4d2b993f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Mean accuracy: 0.6464489795918367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression #\n",
        "# Calculate Logistic Regression f1 score #\n",
        "f1_scores_LR = []\n",
        "# Perform k-fold stratified cross-validation\n",
        "for train_index, test_index in skf.split(x_, y):\n",
        "    X_train, X_test = x_.iloc[train_index], x_.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index] \n",
        "    model.fit(X_train, y_train) # Necessary code to compute the predictions using your classifier.\n",
        "    y_pred = model.predict(X_test)\n",
        "    # Compute the weighted-average F1-score for this fold\n",
        "    fold_f1_score = f1_score(y_test, y_pred, average='weighted')\n",
        "    f1_scores_LR.append(fold_f1_score)\n",
        "# Calculate the mean F1-score across all folds\n",
        "mean_weighted_f1_score = np.mean(f1_scores_LR)\n",
        "print(\"Logistic Regression - Mean weighted-average F1-score across\", 5, \"folds:\", mean_weighted_f1_score)"
      ],
      "metadata": {
        "id": "CVAxOsTssir1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM #\n",
        "# Training and mean_accuracy #\n",
        "skf = StratifiedKFold(n_splits=5)  #the number of folds is 5\n",
        "accuracy_scores = []\n",
        "for train_index, test_index in skf.split(x_, y):\n",
        "  X_train, X_test = x_.iloc[train_index], x_.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]   \n",
        "  svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "  svm.fit(X_train, y_train)\n",
        "  y_pred = svm.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  accuracy_scores.append(accuracy)\n",
        "# Compute the mean accuracy across all folds\n",
        "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "print(\"SVM - Mean accuracy:\", mean_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "J5p7lbU3iazx",
        "outputId": "c0c6d93d-9b40-460d-b29a-75d4ea49891b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-fd69a33b926b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m     def __array_wrap__(\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '12.0m'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM #\n",
        "# Calculate SVM f1 score #\n",
        "f1_scores_SVM = []\n",
        "# Perform k-fold stratified cross-validation\n",
        "for train_index, test_index in skf.split(x_, y):\n",
        "    X_train, X_test = x_.iloc[train_index], x_.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index] \n",
        "    svm.fit(X_train, y_train) # Necessary code to compute the predictions using your classifier.\n",
        "    y_pred = svm.predict(X_test)\n",
        "    # Compute the weighted-average F1-score for this fold\n",
        "    fold_f1_score = f1_score(y_test, y_pred, average='weighted')\n",
        "    f1_scores_SVM.append(fold_f1_score)\n",
        "# Calculate the mean F1-score across all folds\n",
        "mean_weighted_f1_score = np.mean(f1_scores_SVM)\n",
        "print(\"SVM - Mean weighted-average F1-score across\", 5, \"folds:\", mean_weighted_f1_score)"
      ],
      "metadata": {
        "id": "IUSzSxPT7UPK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}