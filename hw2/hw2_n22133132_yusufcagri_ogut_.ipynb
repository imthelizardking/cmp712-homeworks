{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k-1Dn8_kYdg"
      },
      "source": [
        "### HW2 - Multinomial Logistic Regression & SVMs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdX7Rlk5kYdn"
      },
      "source": [
        "### Training and Evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect gdrive for train/test datasets:"
      ],
      "metadata": {
        "id": "7jzAbe3u6Doe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # import lib\n",
        "drive.mount(\"/content/gdrive\") # mount gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnXWIu7ddxm3",
        "outputId": "a842c49f-6a5e-4340-e6ae-9e4b3dc68b2a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries:"
      ],
      "metadata": {
        "id": "isHlEzNW6G9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from pandas import *\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "MOtNL3x8cwW4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read Data:"
      ],
      "metadata": {
        "id": "v7gbLRAC6Moq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sTrainAdd = \"/content/gdrive/MyDrive/MsC/cmp712/hw2/train.csv\" # address of train.csv on gdrive \n",
        "sTestAdd = \"/content/gdrive/MyDrive/MsC/cmp712/hw2/test.csv\" # address of train.csv on gdrive \n",
        "data_training = read_csv(sTrainAdd)\n",
        "data_test = read_csv(sTestAdd)"
      ],
      "metadata": {
        "id": "vG_WJMtAcw64"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess Data:"
      ],
      "metadata": {
        "id": "mYp7VXm56Q9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data Preprocessing\n",
        "temp = data_training.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "sClass = \"type\"\n",
        "x_training = DataFrame()\n",
        "y_training = DataFrame()\n",
        "for idxColumns in range(nColumns):\n",
        "  temp1 = data_training.iloc[:, idxColumns]\n",
        "  if temp1._name==sClass:\n",
        "    y_training = y_training.append(temp1)\n",
        "  else:\n",
        "    x_training = x_training.append(temp1)\n",
        "x_training = x_training.T\n",
        "y_training = y_training.T\n",
        "# Test Data Preprocessing\n",
        "temp = data_test.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "sClass = \"type\"\n",
        "x_test = DataFrame()\n",
        "y_test = DataFrame()\n",
        "for idxColumns in range(nColumns):\n",
        "  temp1 = data_test.iloc[:, idxColumns]\n",
        "  if temp1._name==sClass:\n",
        "    y_test = y_test.append(temp1)\n",
        "  else:\n",
        "    x_test = x_test.append(temp1)\n",
        "x_test = x_test.T\n",
        "y_test = y_test.T"
      ],
      "metadata": {
        "id": "7DMrRdU4fF1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa68bcd-33ca-49d4-b245-07fd648915f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  y_training = y_training.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_training = x_training.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n",
            "<ipython-input-5-9ae2246f050c>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  x_test = x_test.append(temp1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode Datasets:"
      ],
      "metadata": {
        "id": "sCsaUTiG6TC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix Length Feature (remove 'm' in the end and convert string to float)\n",
        "# Training:\n",
        "temp = data_training.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "for idx in range(nRows):\n",
        "  temp = x_training.length[idx]\n",
        "  if isinstance(temp, str):\n",
        "    x_training.length[idx] = float(temp[:-1])\n",
        "  elif math.isnan(temp):\n",
        "    x_training.length[idx] = 9999\n",
        "# Test:\n",
        "temp = data_test.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "for idx in range(nRows):\n",
        "  temp = x_test.length[idx]\n",
        "  if isinstance(temp, str):\n",
        "    x_test.length[idx] = float(temp[:-1])\n",
        "  elif math.isnan(temp):\n",
        "    x_test.length[idx] = 9999"
      ],
      "metadata": {
        "id": "zHZxelLK_lhA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess \"taxonomy\" label for MultiLabelBinarizer\n",
        "temp = x_training.taxonomy\n",
        "nRows = temp.shape\n",
        "nRows = nRows[0]\n",
        "for sample in range(nRows): \n",
        "  x_training.taxonomy[sample] = x_training.taxonomy[sample].split()\n",
        "temp = x_test.taxonomy\n",
        "nRows = temp.shape\n",
        "nRows = nRows[0]\n",
        "unique_list = []\n",
        "for sample in range(nRows): \n",
        "  x_test.taxonomy[sample] = x_test.taxonomy[sample].split()"
      ],
      "metadata": {
        "id": "W3AKZYjxglNv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot Encoding for Training Dataset:\n",
        "le = LabelEncoder() # create label object\n",
        "mle = MultiLabelBinarizer()\n",
        "x_training.diet = le.fit_transform(x_training.diet)\n",
        "x_training.lived_in = le.fit_transform(x_training.lived_in)\n",
        "x_training.period = le.fit_transform(x_training.period)\n",
        "x_training.named_by = le.fit_transform(x_training.named_by)\n",
        "#x_training.taxonomy = le.fit_transform(x_training.taxonomy)\n",
        "x_training.taxonomy = mle.fit_transform(x_training.taxonomy)\n",
        "x_training.species = le.fit_transform(x_training.species)\n",
        "# Limit dataset #\n",
        "x_training_processed = x_training.drop(columns=['id', 'name', 'link']) # x_, argument used in training\n",
        "print(x_training_processed)\n",
        "# One-hot Encoding for Test Dataset:\n",
        "x_test.diet = le.fit_transform(x_test.diet)\n",
        "x_test.lived_in = le.fit_transform(x_test.lived_in)\n",
        "x_test.period = le.fit_transform(x_test.period)\n",
        "x_test.named_by = le.fit_transform(x_test.named_by)\n",
        "#x_test.taxonomy = le.fit_transform(x_test.taxonomy)\n",
        "x_test.taxonomy = mle.fit_transform(x_test.taxonomy)\n",
        "x_test.species = le.fit_transform(x_test.species)\n",
        "# Limit dataset, drop id, name and link as they will not be used in training #\n",
        "x_test_processed = x_test.drop(columns=['id', 'name', 'link']) # x_, argument used in training\n",
        "print(x_test_processed)"
      ],
      "metadata": {
        "id": "eC9evK1ZOUoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36331774-4b30-4caa-ec6c-926242e7801e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     diet  period  lived_in length  taxonomy  named_by  species\n",
            "0       0     108        25   9999         0        76       61\n",
            "1       2     108         1   5.15         0        11       95\n",
            "2       1      65         5   12.0         0       212      188\n",
            "3       1      43        24   21.0         0        64      181\n",
            "4       1      21        25   10.0         0        22       24\n",
            "..    ...     ...       ...    ...       ...       ...      ...\n",
            "241     1      11        13   9999         0       186      184\n",
            "242     1      10         2    3.0         0       161      120\n",
            "243     0      14         5    0.8         0       203      222\n",
            "244     0      42         1    7.6         0        14      182\n",
            "245     3     112        19   12.0         0        70      170\n",
            "\n",
            "[246 rows x 7 columns]\n",
            "    diet  period  lived_in length  taxonomy  named_by  species\n",
            "0      1      18        13    5.0         0        36       19\n",
            "1      1      41        17   23.0         0         8       51\n",
            "2      0      24        17    8.6         0        26       32\n",
            "3      0       2        17   12.0         0        50        6\n",
            "4      2      53        19    3.0         0        58       23\n",
            "..   ...     ...       ...    ...       ...       ...      ...\n",
            "57     1      51         2    5.0         0        10       50\n",
            "58     1      38        10    6.0         0        29       43\n",
            "59     0      39        11    8.1         0        47        1\n",
            "60     1      22         1    6.0         0        59       60\n",
            "61     1      22         1    3.0         0        49       58\n",
            "\n",
            "[62 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression #\n",
        "# Training and mean_accuracy #\n",
        "skf = StratifiedKFold(n_splits=5)  #the number of folds is 5\n",
        "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "accuracy_scores = []\n",
        "for train_index, test_index in skf.split(x_training_processed, y_training):\n",
        "  X_train, X_test = x_training_processed.iloc[train_index], x_training_processed.iloc[test_index]\n",
        "  y_train, y_test = y_training.iloc[train_index], y_training.iloc[test_index]  \n",
        "  model.fit(X_train, y_train)\n",
        "  accuracy = model.score(X_test, y_test)\n",
        "  accuracy_scores.append(accuracy)\n",
        "# Compute the mean accuracy across all folds\n",
        "np.savetxt('training_LR.csv', model.predict(x_training_processed), delimiter=',', fmt='%s') # save result to text\n",
        "np.savetxt('test_LR.csv', model.predict(x_test_processed), delimiter=',', fmt='%s') # save result to text\n",
        "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)"
      ],
      "metadata": {
        "id": "vCAAOQ-VrU5T",
        "outputId": "9984b3e2-bac9-4bb3-e372-fbbf0f4aef21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Mean accuracy: 0.5157551020408163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression - F1 Score and Confusion Matrix\n",
        "f1_scores_LR = []\n",
        "confusion_matrix_LR = []\n",
        "# Perform k-fold stratified cross-validation\n",
        "for train_index, test_index in skf.split(x_training_processed, y_training):\n",
        "    X_train, X_test = x_training_processed.iloc[train_index], x_training_processed.iloc[test_index]\n",
        "    y_train, y_test = y_training.iloc[train_index], y_training.iloc[test_index] \n",
        "    model.fit(X_train, y_train) # Necessary code to compute the predictions using your classifier.\n",
        "    y_pred = model.predict(X_test)\n",
        "    # Compute the weighted-average F1-score for this fold\n",
        "    fold_f1_score = f1_score(y_test, y_pred, average='weighted')\n",
        "    f1_scores_LR.append(fold_f1_score)\n",
        "    fold_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "    confusion_matrix_LR.append(fold_confusion_matrix)\n",
        "# Calculate the mean F1-score across all folds\n",
        "mean_weighted_f1_score = np.mean(f1_scores_LR)"
      ],
      "metadata": {
        "id": "CVAxOsTssir1",
        "outputId": "c50f070e-eba6-4418-d086-eff9bb2eaa30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Mean weighted-average F1-score across 5 folds: 0.5050917807653164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logistic Regression - Mean accuracy:\", mean_accuracy)\n",
        "print(\"Logistic Regression - Mean weighted-average F1-score across\", 5, \"folds:\", mean_weighted_f1_score)\n",
        "print(\"Logistic Regression - Confusion Matrix\", confusion_matrix_LR)"
      ],
      "metadata": {
        "id": "fhdmIwkwek83",
        "outputId": "f1f61ab3-c088-47be-ee96-6e179dcee775",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Mean weighted-average F1-score across 5 folds: 0.5050917807653164\n",
            "Logistic Regression - Confusion Matrix [array([[1, 0, 2, 0, 2, 0],\n",
            "       [0, 2, 3, 0, 0, 0],\n",
            "       [1, 0, 6, 0, 2, 0],\n",
            "       [0, 0, 0, 7, 1, 2],\n",
            "       [0, 0, 1, 1, 9, 0],\n",
            "       [1, 1, 0, 1, 0, 7]]), array([[1, 0, 3, 0, 1, 0],\n",
            "       [0, 3, 1, 0, 0, 0],\n",
            "       [2, 1, 4, 0, 2, 0],\n",
            "       [0, 0, 1, 5, 1, 3],\n",
            "       [2, 0, 2, 1, 3, 3],\n",
            "       [0, 0, 0, 6, 1, 3]]), array([[1, 0, 2, 0, 2, 0],\n",
            "       [0, 4, 0, 0, 0, 0],\n",
            "       [1, 1, 7, 0, 0, 0],\n",
            "       [0, 0, 0, 7, 1, 2],\n",
            "       [0, 0, 0, 1, 6, 4],\n",
            "       [0, 0, 0, 5, 1, 4]]), array([[1, 0, 1, 0, 4, 0],\n",
            "       [0, 3, 1, 0, 0, 0],\n",
            "       [0, 1, 6, 0, 3, 0],\n",
            "       [0, 0, 0, 2, 2, 5],\n",
            "       [0, 0, 0, 1, 9, 1],\n",
            "       [0, 0, 0, 6, 2, 1]]), array([[1, 0, 1, 0, 3, 0],\n",
            "       [0, 4, 1, 0, 0, 0],\n",
            "       [2, 1, 6, 0, 1, 0],\n",
            "       [0, 0, 0, 5, 2, 2],\n",
            "       [1, 0, 1, 1, 6, 2],\n",
            "       [0, 0, 0, 5, 1, 3]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM:"
      ],
      "metadata": {
        "id": "3RkJ3ulfEglW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM #\n",
        "# Training and mean_accuracy #\n",
        "x_training_processed_SVM = x_training_processed\n",
        "x_test_processed_SVM = x_test_processed\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True)  # the number of folds is 3\n",
        "model_SVM = SVC(kernel = 'linear', decision_function_shape='ovo')\n",
        "accuracy_scores = []\n",
        "for train_index, test_index in skf.split(x_training_processed_SVM, y_training):\n",
        "  X_train, X_test = x_training_processed_SVM.iloc[train_index], x_training_processed_SVM.iloc[test_index]\n",
        "  y_train, y_test = y_training.iloc[train_index], y_training.iloc[test_index]\n",
        "  model_SVM.fit(X_train, y_train)\n",
        "  y_pred = model_SVM.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  accuracy_scores.append(accuracy)\n",
        "# Compute the mean accuracy across all folds\n",
        "np.savetxt('training_SVM.csv', model_SVM.predict(x_training_processed_SVM), delimiter=',', fmt='%s') # save result to text\n",
        "np.savetxt('test_SVM.csv', model_SVM.predict(x_test_processed_SVM), delimiter=',', fmt='%s') # save result to text\n",
        "mean_accuracy_SVM = sum(accuracy_scores) / len(accuracy_scores)\n",
        "print(\"SVM - Mean accuracy:\", mean_accuracy_SVM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5p7lbU3iazx",
        "outputId": "0fabba78-ba33-4722-ab96-779dd2897b42"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM - Mean accuracy: 0.4268292682926829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate SVM F1 score and Confusion Matrix\n",
        "f1_scores_SVM = []\n",
        "confusion_matrix_SVM = []\n",
        "# Perform k-fold stratified cross-validation\n",
        "for train_index, test_index in skf.split(x_training_processed_SVM, y_training):\n",
        "    X_train, X_test = x_training_processed_SVM.iloc[train_index], x_training_processed_SVM.iloc[test_index]\n",
        "    y_train, y_test = y_training.iloc[train_index], y_training.iloc[test_index] \n",
        "    model_SVM.fit(X_train, y_train) # Necessary code to compute the predictions using your classifier.\n",
        "    y_pred = model_SVM.predict(X_test)\n",
        "    # Compute the weighted-average F1-score for this fold\n",
        "    fold_f1_score_svm = f1_score(y_test, y_pred, average='weighted')\n",
        "    f1_scores_SVM.append(fold_f1_score_svm)\n",
        "    fold_confusion_matrix_SVM = confusion_matrix(y_test, y_pred)\n",
        "    confusion_matrix_SVM.append(fold_confusion_matrix_SVM)\n",
        "# Calculate the mean F1-score across all folds\n",
        "mean_weighted_f1_score_SVM = np.mean(f1_scores_SVM)\n",
        "print(\"SVM - Mean weighted-average F1-score across\", 5, \"folds:\", mean_weighted_f1_score_SVM)"
      ],
      "metadata": {
        "id": "IUSzSxPT7UPK",
        "outputId": "3ff86279-a709-4ff8-ed70-1909b75ce832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM - Mean weighted-average F1-score across 5 folds: 0.4013251078409716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SVM - Mean accuracy:\", mean_accuracy_SVM)\n",
        "print(\"SVM - Mean weighted-average F1-score across\", 5, \"folds:\", mean_weighted_f1_score_SVM)\n",
        "print(\"Logistic Regression - Confusion Matrix\", confusion_matrix_SVM)"
      ],
      "metadata": {
        "id": "n-_4F8nyt3Bk",
        "outputId": "26d5c077-2301-4b0f-ea49-ebe07a65e1f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM - Mean accuracy: 0.4268292682926829\n",
            "SVM - Mean weighted-average F1-score across 5 folds: 0.4013251078409716\n",
            "Logistic Regression - Confusion Matrix [array([[ 1,  0,  7,  0,  0,  1],\n",
            "       [ 0,  0,  4,  0,  1,  2],\n",
            "       [ 0,  0, 13,  0,  1,  1],\n",
            "       [ 0,  0,  1, 13,  2,  0],\n",
            "       [ 0,  0,  9,  0,  9,  1],\n",
            "       [ 0,  0,  2,  1,  0, 13]]), array([[ 0,  0,  8,  0,  1,  0],\n",
            "       [ 0,  0,  5,  0,  2,  0],\n",
            "       [ 0,  0, 13,  0,  3,  0],\n",
            "       [ 1,  0,  1, 11,  2,  1],\n",
            "       [ 0,  0, 11,  0,  7,  0],\n",
            "       [ 0,  0,  1, 11,  4,  0]]), array([[ 0,  1,  5,  0,  2,  0],\n",
            "       [ 0,  0,  4,  0,  4,  0],\n",
            "       [ 0,  0, 10,  0,  6,  0],\n",
            "       [ 0,  2,  0,  6,  1,  7],\n",
            "       [ 0,  1,  5,  0, 12,  0],\n",
            "       [ 0,  2,  0,  5,  5,  4]])]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}