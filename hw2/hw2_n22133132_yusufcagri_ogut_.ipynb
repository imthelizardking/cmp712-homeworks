{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k-1Dn8_kYdg"
      },
      "source": [
        "### HW2 - Multinomial Logistic Regression & SVMs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdX7Rlk5kYdn"
      },
      "source": [
        "### Training and Evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect gdrive for train/test datasets:"
      ],
      "metadata": {
        "id": "7jzAbe3u6Doe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # import lib\n",
        "drive.mount(\"/content/gdrive\") # mount gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnXWIu7ddxm3",
        "outputId": "d31a6423-2e87-48f3-c868-f5ed555c3d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries:"
      ],
      "metadata": {
        "id": "isHlEzNW6G9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from pandas import *\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "MOtNL3x8cwW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read Data:"
      ],
      "metadata": {
        "id": "v7gbLRAC6Moq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sTrainAdd = \"/content/gdrive/MyDrive/MsC/cmp712/hw2/train.csv\" # address of train.csv on gdrive \n",
        "sTestAdd = \"/content/gdrive/MyDrive/MsC/cmp712/hw2/test.csv\" # address of train.csv on gdrive \n",
        "data_training = read_csv(sTrainAdd)\n",
        "data_test = read_csv(sTestAdd)"
      ],
      "metadata": {
        "id": "vG_WJMtAcw64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess Data:"
      ],
      "metadata": {
        "id": "mYp7VXm56Q9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data Preprocessing\n",
        "temp = data_training.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "sClass = \"type\"\n",
        "x_training = DataFrame()\n",
        "y_training = DataFrame()\n",
        "for idxColumns in range(nColumns):\n",
        "  temp1 = data_training.iloc[:, idxColumns]\n",
        "  if temp1._name==sClass:\n",
        "    y_training = y_training.append(temp1)\n",
        "  else:\n",
        "    x_training = x_training.append(temp1)\n",
        "x_training = x_training.T\n",
        "y_training = y_training.T\n",
        "# Test Data Preprocessing\n",
        "temp = data_test.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "sClass = \"type\"\n",
        "x_test = DataFrame()\n",
        "y_test = DataFrame()\n",
        "for idxColumns in range(nColumns):\n",
        "  temp1 = data_test.iloc[:, idxColumns]\n",
        "  if temp1._name==sClass:\n",
        "    y_test = y_test.append(temp1)\n",
        "  else:\n",
        "    x_test = x_test.append(temp1)\n",
        "x_test = x_test.T\n",
        "y_test = y_test.T"
      ],
      "metadata": {
        "id": "7DMrRdU4fF1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode Datasets:"
      ],
      "metadata": {
        "id": "sCsaUTiG6TC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix Length Feature (remove 'm' in the end and convert string to float)\n",
        "# Training:\n",
        "temp = data_training.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "for idx in range(nRows):\n",
        "  temp = x_training.length[idx]\n",
        "  if isinstance(temp, str):\n",
        "    x_training.length[idx] = float(temp[:-1])\n",
        "  elif math.isnan(temp):\n",
        "    x_training.length[idx] = 9999\n",
        "# Test:\n",
        "temp = data_test.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "for idx in range(nRows):\n",
        "  temp = x_test.length[idx]\n",
        "  if isinstance(temp, str):\n",
        "    x_test.length[idx] = float(temp[:-1])\n",
        "  elif math.isnan(temp):\n",
        "    x_test.length[idx] = 9999"
      ],
      "metadata": {
        "id": "zHZxelLK_lhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding (Logistic Regression):\n",
        "# Encoding for Training Dataset:\n",
        "le = LabelEncoder()\n",
        "x_training_LR = x_training\n",
        "x_training_LR.diet = le.fit_transform(x_training_LR.diet)\n",
        "x_training_LR.lived_in = le.fit_transform(x_training_LR.lived_in)\n",
        "x_training_LR.period = le.fit_transform(x_training_LR.period)\n",
        "x_training_LR.named_by = le.fit_transform(x_training_LR.named_by)\n",
        "x_training_LR.taxonomy = le.fit_transform(x_training_LR.taxonomy)\n",
        "x_training_LR.species = le.fit_transform(x_training_LR.species)\n",
        "# Limit dataset, drop id, name and link as they will not be used in training #\n",
        "x_training_LR = x_training_LR.drop(columns=['id', 'name', 'link']) # x_, argument used in training\n",
        "print(x_training_LR)\n",
        "# Encoding for Test Dataset:\n",
        "x_test_LR = x_test\n",
        "x_test_LR.diet = le.fit_transform(x_test_LR.diet)\n",
        "x_test_LR.lived_in = le.fit_transform(x_test_LR.lived_in)\n",
        "x_test_LR.period = le.fit_transform(x_test_LR.period)\n",
        "x_test_LR.named_by = le.fit_transform(x_test_LR.named_by)\n",
        "x_test_LR.taxonomy = le.fit_transform(x_test_LR.taxonomy)\n",
        "x_test_LR.species = le.fit_transform(x_test_LR.species)\n",
        "# Limit dataset, drop id, name and link as they will not be used in training #\n",
        "x_test_LR = x_test_LR.drop(columns=['id', 'name', 'link']) # x_, argument used in training\n",
        "print(x_test_LR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9u5t-fb1g0H",
        "outputId": "77c89218-b2f2-40d4-ae91-ba8f31576aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     diet  period  lived_in length  taxonomy  named_by  species\n",
            "0       0     108        25   9999         0        76       61\n",
            "1       2     108         1   5.15        34        11       95\n",
            "2       1      65         5   12.0        20       212      188\n",
            "3       1      43        24   21.0        49        64      181\n",
            "4       1      21        25   10.0        17        22       24\n",
            "..    ...     ...       ...    ...       ...       ...      ...\n",
            "241     1      11        13   9999        25       186      184\n",
            "242     1      10         2    3.0        13       161      120\n",
            "243     0      14         5    0.8        79       203      222\n",
            "244     0      42         1    7.6        58        14      182\n",
            "245     3     112        19   12.0        34        70      170\n",
            "\n",
            "[246 rows x 7 columns]\n",
            "    diet  period  lived_in length  taxonomy  named_by  species\n",
            "0      1      18        13    5.0        24        36       19\n",
            "1      1      41        17   23.0        21         8       51\n",
            "2      0      24        17    8.6        43        26       32\n",
            "3      0       2        17   12.0        30        50        6\n",
            "4      2      53        19    3.0        33        58       23\n",
            "..   ...     ...       ...    ...       ...       ...      ...\n",
            "57     1      51         2    5.0        20        10       50\n",
            "58     1      38        10    6.0         9        29       43\n",
            "59     0      39        11    8.1        31        47        1\n",
            "60     1      22         1    6.0         2        59       60\n",
            "61     1      22         1    3.0         3        49       58\n",
            "\n",
            "[62 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression #\n",
        "# Training #\n",
        "skf = StratifiedKFold(n_splits=5)  #the number of folds is 5\n",
        "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "accuracy_scores = []\n",
        "for train_index, test_index in skf.split(x_training_LR, y_training):\n",
        "  X_train, X_test = x_training_LR.iloc[train_index], x_training_LR.iloc[test_index]\n",
        "  y_train, y_test = y_training.iloc[train_index], y_training.iloc[test_index]  \n",
        "  model.fit(X_train, y_train)\n",
        "  accuracy = model.score(X_test, y_test)\n",
        "  accuracy_scores.append(accuracy)\n",
        "# Compute the mean accuracy across all folds\n",
        "np.savetxt('training_LR.csv', model.predict(x_training_LR), delimiter=',', fmt='%s') # save result to text\n",
        "np.savetxt('test_LR.csv', model.predict(x_test_LR), delimiter=',', fmt='%s') # save result to text\n",
        "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)"
      ],
      "metadata": {
        "id": "vCAAOQ-VrU5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression - F1 Score and Confusion Matrix\n",
        "f1_scores_LR = []\n",
        "confusion_matrix_LR = []\n",
        "# Perform k-fold stratified cross-validation\n",
        "for train_index, test_index in skf.split(x_training_LR, y_training):\n",
        "    X_train, X_test = x_training_LR.iloc[train_index], x_training_LR.iloc[test_index]\n",
        "    y_train, y_test = y_training.iloc[train_index], y_training.iloc[test_index] \n",
        "    model.fit(X_train, y_train) # Necessary code to compute the predictions using your classifier.\n",
        "    y_pred = model.predict(X_test)\n",
        "    # Compute the weighted-average F1-score for this fold\n",
        "    fold_f1_score = f1_score(y_test, y_pred, average='weighted')\n",
        "    f1_scores_LR.append(fold_f1_score)\n",
        "    fold_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "    confusion_matrix_LR.append(fold_confusion_matrix)\n",
        "# Calculate the mean F1-score across all folds\n",
        "mean_weighted_f1_score = np.mean(f1_scores_LR)"
      ],
      "metadata": {
        "id": "CVAxOsTssir1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logistic Regression - Mean accuracy:\", mean_accuracy)\n",
        "print(\"Logistic Regression - Mean weighted-average F1-score across\", 5, \"folds:\", mean_weighted_f1_score)\n",
        "print(\"Logistic Regression - Confusion Matrix\", confusion_matrix_LR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhdmIwkwek83",
        "outputId": "56835903-884a-447c-8cc1-6857933244dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Mean accuracy: 0.5157551020408163\n",
            "Logistic Regression - Mean weighted-average F1-score across 5 folds: 0.5050917807653164\n",
            "Logistic Regression - Confusion Matrix [array([[1, 0, 2, 0, 2, 0],\n",
            "       [0, 2, 3, 0, 0, 0],\n",
            "       [1, 0, 6, 0, 2, 0],\n",
            "       [0, 0, 0, 7, 1, 2],\n",
            "       [0, 0, 1, 1, 9, 0],\n",
            "       [1, 1, 0, 1, 0, 7]]), array([[1, 0, 3, 0, 1, 0],\n",
            "       [0, 3, 1, 0, 0, 0],\n",
            "       [2, 1, 4, 0, 2, 0],\n",
            "       [0, 0, 1, 5, 1, 3],\n",
            "       [2, 0, 2, 1, 3, 3],\n",
            "       [0, 0, 0, 6, 1, 3]]), array([[1, 0, 2, 0, 2, 0],\n",
            "       [0, 4, 0, 0, 0, 0],\n",
            "       [1, 1, 7, 0, 0, 0],\n",
            "       [0, 0, 0, 7, 1, 2],\n",
            "       [0, 0, 0, 1, 6, 4],\n",
            "       [0, 0, 0, 5, 1, 4]]), array([[1, 0, 1, 0, 4, 0],\n",
            "       [0, 3, 1, 0, 0, 0],\n",
            "       [0, 1, 6, 0, 3, 0],\n",
            "       [0, 0, 0, 2, 2, 5],\n",
            "       [0, 0, 0, 1, 9, 1],\n",
            "       [0, 0, 0, 6, 2, 1]]), array([[1, 0, 1, 0, 3, 0],\n",
            "       [0, 4, 1, 0, 0, 0],\n",
            "       [2, 1, 6, 0, 1, 0],\n",
            "       [0, 0, 0, 5, 2, 2],\n",
            "       [1, 0, 1, 1, 6, 2],\n",
            "       [0, 0, 0, 5, 1, 3]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM:"
      ],
      "metadata": {
        "id": "3RkJ3ulfEglW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This re-reading dataset in following codeblock is due to my bad coding, i saw that using multilabel binarizer works good for SVM, but not for Log. Reg. (i don't know why)."
      ],
      "metadata": {
        "id": "bPt65Lf1A0B3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_training = read_csv(sTrainAdd)\n",
        "data_test = read_csv(sTestAdd)\n",
        "# Training Data Preprocessing\n",
        "temp = data_training.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "sClass = \"type\"\n",
        "x_training = DataFrame()\n",
        "y_training = DataFrame()\n",
        "for idxColumns in range(nColumns):\n",
        "  temp1 = data_training.iloc[:, idxColumns]\n",
        "  if temp1._name==sClass:\n",
        "    y_training = y_training.append(temp1)\n",
        "  else:\n",
        "    x_training = x_training.append(temp1)\n",
        "x_training = x_training.T\n",
        "y_training = y_training.T\n",
        "# Test Data Preprocessing\n",
        "temp = data_test.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "sClass = \"type\"\n",
        "x_test = DataFrame()\n",
        "y_test = DataFrame()\n",
        "for idxColumns in range(nColumns):\n",
        "  temp1 = data_test.iloc[:, idxColumns]\n",
        "  if temp1._name==sClass:\n",
        "    y_test = y_test.append(temp1)\n",
        "  else:\n",
        "    x_test = x_test.append(temp1)\n",
        "x_test = x_test.T\n",
        "y_test = y_test.T\n",
        "# Fix Length Feature (remove 'm' in the end and convert string to float)\n",
        "# Training:\n",
        "temp = data_training.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "for idx in range(nRows):\n",
        "  temp = x_training.length[idx]\n",
        "  if isinstance(temp, str):\n",
        "    x_training.length[idx] = float(temp[:-1])\n",
        "  elif math.isnan(temp):\n",
        "    x_training.length[idx] = 9999\n",
        "# Test:\n",
        "temp = data_test.iloc[:,:]\n",
        "nRows, nColumns = temp.shape\n",
        "for idx in range(nRows):\n",
        "  temp = x_test.length[idx]\n",
        "  if isinstance(temp, str):\n",
        "    x_test.length[idx] = float(temp[:-1])\n",
        "  elif math.isnan(temp):\n",
        "    x_test.length[idx] = 9999\n",
        "# Encoding (SVM):\n",
        "# Encoding for Training Dataset:\n",
        "le2 = LabelEncoder()\n",
        "mle = MultiLabelBinarizer()\n",
        "x_training_SVM = x_training\n",
        "x_training_SVM.diet = le2.fit_transform(x_training_SVM.diet)\n",
        "x_training_SVM.lived_in = le2.fit_transform(x_training_SVM.lived_in)\n",
        "x_training_SVM.period = le2.fit_transform(x_training_SVM.period)\n",
        "x_training_SVM.named_by = le2.fit_transform(x_training_SVM.named_by)\n",
        "\n",
        "x_training_SVM.taxonomy = mle.fit_transform(x_training_SVM.taxonomy)\n",
        "x_training_SVM.species = le2.fit_transform(x_training_SVM.species)\n",
        "# Limit dataset, drop id, name and link as they will not be used in training #\n",
        "x_training_SVM = x_training_SVM.drop(columns=['id', 'name', 'link']) # x_, argument used in training\n",
        "# Encoding for Test Dataset:\n",
        "x_test_SVM = x_test\n",
        "x_test_SVM.diet = le2.fit_transform(x_test_SVM.diet)\n",
        "x_test_SVM.lived_in = le2.fit_transform(x_test_SVM.lived_in)\n",
        "x_test_SVM.period = le2.fit_transform(x_test_SVM.period)\n",
        "x_test_SVM.named_by = le2.fit_transform(x_test_SVM.named_by)\n",
        "\n",
        "x_test_SVM.taxonomy = mle.fit_transform(x_test_SVM.taxonomy)\n",
        "x_test_SVM.species = le2.fit_transform(x_test_SVM.species)\n",
        "# Limit dataset, drop id, name and link as they will not be used in training #\n",
        "x_test_SVM = x_test_SVM.drop(columns=['id', 'name', 'link']) # x_, argument used in training"
      ],
      "metadata": {
        "id": "IVWMshZbAzvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM #\n",
        "# Training and mean_accuracy #\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True)  # the number of folds is 3\n",
        "model_SVM = SVC(kernel = 'linear', decision_function_shape='ovo')\n",
        "accuracy_scores = []\n",
        "for train_index, test_index in skf.split(x_training_SVM, y_training):\n",
        "  X_train, X_test = x_training_SVM.iloc[train_index], x_training_SVM.iloc[test_index]\n",
        "  y_train, y_test = y_training.iloc[train_index], y_training.iloc[test_index]\n",
        "  model_SVM.fit(X_train, y_train)\n",
        "  y_pred = model_SVM.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  accuracy_scores.append(accuracy)\n",
        "# Compute the mean accuracy across all folds\n",
        "np.savetxt('training_SVM.csv', model_SVM.predict(x_training_SVM), delimiter=',', fmt='%s') # save result to text\n",
        "np.savetxt('test_SVM.csv', model_SVM.predict(x_test_SVM), delimiter=',', fmt='%s') # save result to text\n",
        "mean_accuracy_SVM = sum(accuracy_scores) / len(accuracy_scores)"
      ],
      "metadata": {
        "id": "J5p7lbU3iazx",
        "outputId": "c7603831-466a-4496-ddd0-5ab7444cd9b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate SVM F1 score and Confusion Matrix\n",
        "f1_scores_SVM = []\n",
        "confusion_matrix_SVM = []\n",
        "# Perform k-fold stratified cross-validation\n",
        "for train_index, test_index in skf.split(x_training_SVM, y_training):\n",
        "    X_train, X_test = x_training_SVM.iloc[train_index], x_training_SVM.iloc[test_index]\n",
        "    y_train, y_test = y_training.iloc[train_index], y_training.iloc[test_index] \n",
        "    model_SVM.fit(X_train, y_train) # Necessary code to compute the predictions using your classifier.\n",
        "    y_pred = model_SVM.predict(X_test)\n",
        "    # Compute the weighted-average F1-score for this fold\n",
        "    fold_f1_score_svm = f1_score(y_test, y_pred, average='weighted')\n",
        "    f1_scores_SVM.append(fold_f1_score_svm)\n",
        "    fold_confusion_matrix_SVM = confusion_matrix(y_test, y_pred)\n",
        "    confusion_matrix_SVM.append(fold_confusion_matrix_SVM)\n",
        "# Calculate the mean F1-score across all folds\n",
        "mean_weighted_f1_score_SVM = np.mean(f1_scores_SVM)\n",
        "print(\"SVM - Mean weighted-average F1-score across\", 5, \"folds:\", mean_weighted_f1_score_SVM)"
      ],
      "metadata": {
        "id": "IUSzSxPT7UPK",
        "outputId": "2a540a1a-e00f-4198-f1b4-a68f122af195",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM - Mean weighted-average F1-score across 5 folds: 0.3393613095202855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SVM - Mean accuracy:\", mean_accuracy_SVM)\n",
        "print(\"SVM - Mean weighted-average F1-score across\", 5, \"folds:\", mean_weighted_f1_score_SVM)\n",
        "print(\"Logistic Regression - Confusion Matrix\", confusion_matrix_SVM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-_4F8nyt3Bk",
        "outputId": "b422d71d-93a4-4149-9ea6-b1b865e6100d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM - Mean accuracy: 0.4146341463414634\n",
            "SVM - Mean weighted-average F1-score across 5 folds: 0.3393613095202855\n",
            "Logistic Regression - Confusion Matrix [array([[ 0,  0,  6,  0,  3,  0],\n",
            "       [ 0,  0,  5,  0,  2,  0],\n",
            "       [ 0,  0, 12,  0,  3,  0],\n",
            "       [ 0,  0,  1,  6,  2,  7],\n",
            "       [ 0,  0,  7,  0, 12,  0],\n",
            "       [ 0,  0,  0, 10,  4,  2]]), array([[ 0,  0,  6,  0,  1,  2],\n",
            "       [ 1,  0,  2,  0,  0,  4],\n",
            "       [ 3,  0,  2,  0,  3,  8],\n",
            "       [ 0,  0,  0, 14,  2,  0],\n",
            "       [ 1,  0, 11,  0,  5,  1],\n",
            "       [ 0,  0,  0,  2,  0, 14]]), array([[ 0,  0,  5,  0,  3,  0],\n",
            "       [ 0,  0,  5,  0,  3,  0],\n",
            "       [ 0,  0, 11,  0,  5,  0],\n",
            "       [ 0,  0,  2, 12,  2,  0],\n",
            "       [ 0,  0,  8,  0, 10,  0],\n",
            "       [ 0,  0,  1, 13,  2,  0]])]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}